summary(fit)$coef[3, 1]
summary(fit)
summary(fit)$coef[2, 1]
mtcars$cyl <- factor(mtcars$cyl)
fit <- lm(mtcars$mpg ~ mtcars$cyl + mtcars$wt)
fit2 <- lm(mtcars$mpg ~ mtcars$cyl)
summary(fit)
summary(fit2)
fit3 <- lm(mtcars$mpg ~ mtcars$cyl + mtcars$wt + mtcars$cyl:mtcars$wt)
anova(fit, fit3)
fit4 <- lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
summary(fit4)
?mtcars
summary(fit)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit <- lm(y ~ x)
hatvalues(fit)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
dfbetas(fit)
dfbetas(fit)[,2]
hatvalues(fit)
dfbetas(fit)[5,]
data(mtcars)
?mtcars
library("ggplot2", lib.loc="~/R/win-library/3.2")
library(knitr)
install.packages("knitr")
install.packages("pdflatex")
install.packages("MiKTeX")
install.packages("pdflatex")
?cor
cor(mtcars, mtcars$mpg)
cor(mtcars, mtcars$mpg)[-1,]
cor(mtcars$mpg, mtcars)
cor(mtcars, mtcars$mpg)
summary(mtcars)
summary(aov(mpg ~ ., data=mtcars))
mtcars$cyl <- factor(mtcars$cyl)
mtcars$am <- factor(mtcars$am,labels=c('Automatic','Manual'))
cor(mtcars$mpg, mtcars)
cor(mtcars$mpg, mtcars)
cor(mtcars, mtcars$mpg)
data(mtcars)
cor(mtcars, mtcars$mpg)
cor(mtcars, mtcars$mpg)
aggregate(mpg~am, data = mtcars, mean)
?mtcars
?cor
fit <- lm(mpg~am, data=mtcars)
summary(fit)
fit2 <- lm(mpg ~ am + wt + hp + cyl, data = mtcars)
summary(fit2)
anova(fit1,fit2)
anova(fit,fit2)
par(mfrow=c(2, 2))
plot(fit)
par(mfrow=c(2, 2))
plot(fit2)
t.test(mpg ~ am, data = mtcars)
mtcars$am <- factor(mtcars$am,labels=c("Automatic","Manual"))
data(mtcars)
aggregate(mpg ~ am, data = mtcars, mean)
cor(mtcars, mtcars$mpg)
mtcars$am <- factor(mtcars$am,labels=c("Automatic","Manual"))
mtcars$cyl  <- as.factor(mtcars$cyl)
fit1 <- lm(mpg ~ am, data = mtcars)
summary(fit1)
fit2 <- lm(mpg ~ am + wt + hp + cyl, data = mtcars)
summary(fit2)
anova(fit1,fit2)
fit2 <- lm(mpg ~ am + wt + hp + cyl, data = mtcars)
summary(fit2)
anova(fit1,fit2)
par(mfrow = c(2, 2))
plot(fit2)
pairs(mpg ~ ., data = mtcars)
?shuttle
data(shuttle)
library(MASS)
data(shuttle)
?shuttle
head(shuttle)
shuttle2$use2<-as.numeric(shuttle2$use=='auto')
shuttle2<-shuttle
shuttle2$use2<-as.numeric(shuttle2$use=='auto')
View(shuttle2)
shuttle2$wind<-factor(shuttle2$wind)
View(shuttle2)
str(shuttle2)
str(shuttle)
fit<-glm(use ~ wind - 1, family = "binomial", data = shuttle)
summary(fit)$coef
exp(coef(fit))
shuttle$useNum[shuttle$use == 'auto'] <- 1
shuttle$useNum[shuttle$use == 'noauto'] <- 0
head(shuttle)
shuttle$windFactor <- factor(shuttle$wind)
head(shuttle)
logAutolander1 <- glm(shuttle$useNum ~ shuttle$windFactor, family='binomial')
summary(logAutolander1)
exp(logAutolander1$coeff)
exp(confint(logAutolander1))
shuttle$use <- factor(shuttle$use, levels = c("auto", "noauto"), labels = c(1, 0))
fit1 <- glm(use ~ wind - 1, data = shuttle, family = "binomial")
summary(fit1)
windhead <- fit1$coef[1]
windtail <- fit1$coef[2]
exp(windtail)/exp(windhead)
data(shuttle)
fit <- glm(use ~ wind - 1, data = shuttle, family = "binomial")
summary(fit)
windhead <- fit$coef[1]
windtail <- fit$coef[2]
exp(windtail)/exp(windhead)
exp(windhead)/exp(windtail)
data(shuttle)
fit2 <- glm(use ~ wind + magn - 1, data = shuttle, family = "binomial")
summary(fit)
summary(fit2)
windhead2 <- fit2$coef[1]
windtail2 <- fit2$coef[2]
exp(windtail2)/exp(windhead2)
data(shuttle)
fit <- glm(auto ~ wind,  binomial,  shuttle)
shuttle$auto <- as.numeric(shuttle$use=="auto")
fit <- glm(auto ~ wind,  binomial,  shuttle)
fit3 <- glm(1-auto ~ wind,  binomial, shuttle)
fit$coefficients
fit3$coefficients
fit3 <- glm(I(1-auto) ~ wind,  binomial, shuttle)
fit3$coefficients
data(InsectSprays)
fit <- glm(count ~ spray  - 1, family = "poisson", data = InsectSprays)
exp(fit$coef[1])/exp(fit$coef[2])
summary(fit)
x <- -5:5
y <- c(5.12, 3.93, 2.67, 1.87, 0.52, 0.08, 0.93, 2.05, 2.54, 3.87, 4.97)
knots<-c(0)
splineTerms<-sapply(knots, function(knot)(x > knot)*(x - knot))
xMat<-cbind(1,x,splineTerms)
yhat<-predict(lm(y~xMat-1))
plot(x,y,frame=FALSE,pch=21,bg="lightblue",cex=2)
lines(x,yhat,col="red",lwd=2)
swirl()
library(swirl)
swirl()
lm(data = swiss, Fertility ~ .)
all <- lm(Fertility ~ ., data = swiss)
summary(all)
lm(Fertility ~ Agriculture, data = swiss)
summary(lm(Fertility ~ Agriculture, data = swiss))
cor(swiss$Examination, swiss$Education)
cor(swiss$Agriculture, swiss$Education)
makelms()
ec <- sum(swiss$Examination + swiss$Catholic)
ec <- swiss$Examination + swiss$Catholic
efit <- lm(Fertility ~ )
efit <- lm(Fertility ~ Agriculture + Catholic + Education + Examination +Infant.Mortality + ec, data = swiss)
coef(all) - coef(efit)
all$coefficients - efit$coefficients
6
dim(InsectSprays)
head(InsectSprays)
head(InsectSprays, 15)
sA
summary(InsectSprays[,2])
?sapply
sapply(InsectSprays, function(x) classes(x))
sapply(InsectSprays)
sapply(m, 2, function(x) is.matrix(x))
sapply(m, function(x) is.matrix(x), 2)
sapply(InsectSprays, function(x) is.matrix(x), 2)
sapply(InsectSprays, function(x) is.matrix(x))
sapply(InsectSprays, class)
fit <- lm(count ~ spray, data = InsectSprays)
fit$coef
summary(fit)$coef
est <- summary(fit)$coef[,1]
mean(sA)
mean(sB)
nfit <- lm(count ~ spray - 1, data = InsectSprays)
summary(nfit)$coef
?relevel
relevel(InsectSprays$spray, C)
relevel(InsectSprays$spray, "C")
spray2 <- relevel(InsectSprays$spray, "C")
fit2 <- lm(count ~ spray2 - 1, data = InsectSprays)
fit2 <- lm(count ~ spray2, data = InsectSprays)
summary(fit2)$coef[,1]
summary(fit2)$coef
mean(sC)
(fit$coef[2] - fit$coef[3])/ 1.6011
install.packages("caret")
library("caret", lib.loc="~/R/win-library/3.2")
?createDataPartition
?paste0
?getwd
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
names <- colnames(concrete)
names <- names[-length(names)]
featurePlot(x = training[, names], y = training$CompressiveStrength, plot = "pairs")
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
View(concrete)
View(mixtures)
View(testing)
View(mixtures)
View(training)
qplot(CompressiveStrength, Cement, data=concrete)
?qplot
qplot(CompressiveStrength, Cement, data=concrete)
qplot(Superplasticizer, data=training)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
View(training)
?grep
grep('^IL', x = names(training))
ss <- training[,grep('^IL', x = names(training))]
?preProcess
preProc <- preProcess(ss, method='pca', thresh=0.9)
preProc
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
ss <- grep("^IL", colnames(training))
predictors_ss <- predictors[, ss]
View(predictors_ss)
ss <- grep('^IL', colnames(training))
predictors_ss <- predictors[, ss]
View(predictors_ss)
ss <- training[,grep('^IL', x = names(training))]
View(ss)
model1 <- data.frame(ss, diagnosis)
model1 <- data.frame(diagnosis, ss)
IL_str <- grep("^IL", colnames(training), value = TRUE)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
IL_str <- grep("^IL", colnames(training), value = TRUE)
predictors_IL <- predictors[, IL_str]
View(predictors_IL)
df <- data.frame(predictors_IL, diagnosis)
View(df)
new_testing <- testing[, c(names(testing)[IL_str], "diagnosis")]
inTrain = createDataPartition(df$diagnosis, p = 3/4)[[1]]
training = df[inTrain, ]
testing = df[-inTrain, ]
non_pca_model <- train(diagnosis ~ ., data=new_training, method="glm")
non_pca_model <- train(diagnosis ~ ., data=training, method="glm")
install.packages("e1071")
non_pca_model <- train(diagnosis ~ ., data=training, method="glm")
non_pca_model
non_pca_result <- confusionMatrix(new_testing[, 13], predict(non_pca_model, new_testing[, -13]))
non_pca_result <- confusionMatrix(new_testing[, 13], predict(non_pca_model, testing[, -13]))
non_pca_result <- confusionMatrix(testing[, 13], predict(non_pca_model, testing[, -13]))
non_pca_result
pc_training_obj <- preProcess(training[, -13], method='pca', thresh=0.8)
non_pca_result
pc_training_preds <- predict(pc_training_obj, training[, -13])
pc_testing_preds <- predict(pc_training_obj, testing[, -13])
pca_model <- train(training$diagnosis ~ ., data=pc_training_preds, method="glm")
pca_result <- confusionMatrix(testing[, 13], predict(pca_model, pc_testing_preds))
pca_result
non_pca_result
install.packages("ElemStatLearn")
install.packages("pgmm")
install.packages("rpart")
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
set.seed(125)
inTrain <- createDataPartition(y=segmentationOriginal$Case,p=0.7, list=FALSE)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
dim(training); dim(testing)
modFit <- train(Case ~ .,method="rpart",data=training)
fancyRpartPlot(model$finalModel)
library("e1071", lib.loc="~/R/win-library/3.2")
fancyRpartPlot(model$finalModel)
install.packages("rattle")
library("rattle", lib.loc="~/R/win-library/3.2")
fancyRpartPlot(model$finalModel)
fancyRpartPlot(modFit$finalModel)
library("rpart", lib.loc="~/R/win-library/3.2")
fancyRpartPlot(modFit$finalModel)
install.packages("rpart.plot")
library("rpart.plot", lib.loc="~/R/win-library/3.2")
fancyRpartPlot(modFit$finalModel)
summary(segmentationOriginal$Case)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
library(rattle)
summary(segmentationOriginal$Case)
?grep
inTrain <- grep("Train",segmentationOriginal$Case)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
set.seed(125)
fit <- train(Class~.,data=training,method="rpart")
fancyRpartPlot(fit$finalModel)
View(training)
which(colnames(training)=="TotalIntenCh2")
which(colnames(training)=="FiberWidthCh1")
which(colnames(training)=="PerimStatusCh1")
View(training)
predData <- training[1:3,]
View(predData)
View(predData)
predData[1,c(103,50,85)]=c(23000,10,2)
predData[2,c(103,50,85)]=c(50000,10,100)
predData[3,c(103,50,85)]=c(57000,8,100)
predict(fit,predData)
View(predData)
View(predData)
library(pgmm)
data(olive)
olive = olive[,-1]
View(olive)
newdata = as.data.frame(t(colMeans(olive)))
View(newdata)
fit <- train(Area~.,data=olive,method="rpart")
fancyRpartPlot(fit$finalModel)
View(olive)
View(newdata)
View(newdata)
pred <- predict(fit,newdata)
summary(olive)
str(olive)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.ss
set.seed(13234)
model <- train(chd~age+alcohol+obesity+tobacco+typea+ldl,data=trainSA,method="glm",family="binomial")
missClass <- function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(trainSA$chd, predict(model, trainSA))
missClass(testSA$chd, predict(model, testSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
str(vowel.train)
vowel.train$y = factor(vowel.train$y)
vowel.test$y = factor(vowel.test$y)
str(vowel.train)
str(vowel.test)
set.seed(33833)
fit <- randomForest(y~.,data=vowel.train)
vowel.rfmodel <- train(y ~ ., data=vowel.train, method="rf")
rfNews()
vowel.rfmodel <- train(y ~ ., data=vowel.train, method="rf")
varImp(vowel.rfmodel)
swirl()
library(swirl)
swirl()
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
set.seed(33833)
vowel.all <-rbind(vowel.train, vowel.test)
vowel.all$y <- as.factor(vowel.all$y)
str(vowel.train)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
fit1 <- train(y ~ ., data = vowel.train, method = "rf")
fit1 <- train(y ~ ., data = vowel.train, method = "rf")
library(caret)
fit1 <- train(y ~ ., data = vowel.train, method = "rf")
rfNews()
fit2 <- train(y ~ ., data = vowel.train, method = "gbm")
install.packages(c("chron", "crayon", "httr", "lme4", "manipulate", "plyr", "rmarkdown", "scales", "stringi"))
install.packages(c("chron", "crayon", "httr", "lme4", "manipulate",
setwd("E:/Temp/BigData")
install.packages(c("chron", "httr", "manipulate"))
install.packages("devtools")
library(devtools)
find_rtools()
find_rtools()
library(devtools)
install_github('slidify', 'ramnathv')
install_github('slidifyLibraries', 'ramnathv')
library(slidify)
install_github('slidify', 'ramnathv')
library("shiny", lib.loc="~/R/win-library/3.2")
library("knitr", lib.loc="~/R/win-library/3.2")
install.packages(c("caret", "chron", "crayon", "curl", "e1071", "ElemStatLearn", "gridExtra", "httr", "manipulate", "R6", "rattle", "RcppEigen", "RCurl", "rpart", "TTR"))
install.packages('devtools')
devtools::install_github('rstudio/shinyapps')
install.packages("stringi")
devtools::install_github('rstudio/shinyapps')
library(shinyapps)
devtools::install_github('rstudio/shinyapps')
library(shinyapps)
shiny::runApp('GitHub/Developing-Data-Products')
shiny::runApp('GitHub/Developing-Data-Products')
shiny::runApp('GitHub/Developing-Data-Products')
shiny::runApp('GitHub/Developing-Data-Products')
shiny::runApp('GitHub/Developing-Data-Products')
shiny::runApp('GitHub/Developing-Data-Products')
shiny::runApp('GitHub/Developing-Data-Products')
shiny::runApp('GitHub/Developing-Data-Products')
shiny::runApp('GitHub/Developing-Data-Products')
shiny::runApp('GitHub/Developing-Data-Products')
shiny::runApp('GitHub/Developing-Data-Products')
shiny::runApp('GitHub/Developing-Data-Products')
shiny::runApp('GitHub/Developing-Data-Products')
shiny::runApp('GitHub/Developing-Data-Products')
shiny::runApp('GitHub/Developing-Data-Products')
shiny::runApp('GitHub/Developing-Data-Products')
shiny::runApp('GitHub/Developing-Data-Products')
shiny::runApp('GitHub/Developing-Data-Products')
shiny::runApp('GitHub/Developing-Data-Products')
shiny::runApp('GitHub/Developing-Data-Products')
shiny::runApp('GitHub/Developing-Data-Products')
install.packages('devtools')
install.packages("devtools")
devtools::install_github('rstudio/shinyapps')
install.packages('devtools')
devtools::install_github('rstudio/shinyapps')
diagnose(70,1.75)
```
bmi <- round(weight/(height^2),digits=2)
---
Body Mass Index (BMI) Calculator
========================================================
What is BMI?
========================================================
The body mass index (BMI), or Quetelet index, is a value derived from the mass (weight) and height of an individual.
The International Classification of adult underweight, overweight and obesity according to BMI:
* BMI <18.5        : Underweight
* BMI [18.5-24.99] : Normal weight
* BMI [25-29.99]   : Overweight
* BMI >=30         : Obesity
How do you calculate it?
========================================================
Formula for calculating the BMI is:
BMI = weight(kg) / height(metres)$^2$
Thus for the next example, the BMI will be:
```{r }
weight=70
height=1.75
BMI<-weight/(height^2)
round(BMI,digits=2)
```
Diagnose
========================================================
The function use for diagnose is:
```{r }
diagnose<-function(weight,height)
{
bmi <- round(weight/(height^2),digits=2)
ifelse(bmi<18.5,"Underweight",ifelse(bmi<25,"Normal weight",ifelse(bmi<30,"Overweight","Obesity")))
}
```
In standard example (weight=70 kg and height=1.75 m) the diagnose is:
```{r }
diagnose(70,1.75)
```
Conclusion
========================================================
The BMI is an attempt to quantify the amount of tissue mass (muscle, fat, and bone) in an individual, and then categorize that person as underweight, normal weight, overweight, or obese based on that value.
BMI categories are generally regarded as a satisfactory tool for measuring whether sedentary individuals are underweight, overweight or obese with various exceptions, such as: athletes, children, the elderly, and the infirm.
Also, the growth of a child is documented against a BMI-measured growth chart. Obesity trends can then be calculated from the difference between the child's BMI and the BMI on the chart.
setwd("~/GitHub/Developing-Data-Products")
setwd("~/GitHub/Developing-Data-Products")
